#数据去重

##目标
	数据去重的目标是让原始数据中出现次数超过一次的数据在输出文件中只出现一次.

##思路
	解决思路是将相同数据的所有记录交给一个Reducer机器执行任务, 无论该数据出现多少次, 只要输出一次即可.
	将真实数据作为MapOutputKey, MapOutputValue为NullWritable.传递给Reducer后, 解析KEYIN即可.

##样例文件
	dedup-one.txt
	11:华山
	12:少林寺
	13:西安
	14:台湾省
	5:凤凰古城
	9:拉萨
	
	dedup-two.txt
	1:北京
	2:上海
	3:山东
	4:广州
	5:凤凰古城
	6:泰山
	7:香港
	8:澳门
	9:拉萨

